Pseudo-Colorization Project Documentation

1. Project Overview:
This project converts grayscale images to color images using a UNet-based neural network. The model predicts 'ab' channels in LAB color space from the grayscale 'L' channel.

Key contributions beyond standard colorization:
- Automatic batch colorization via GUI.
- Scrollable results display.
- Metrics evaluation: PSNR and SSIM.
- Automatic colorization upon image load.

2. Dataset:
Structure:
data/
├── train_black/
├── train_color/
├── test_black/
└── test_color/

- Each grayscale image has a corresponding color image.
- Images resized to 224x224 for training and GUI display.
- Dataset loader handles first 50 test images for GUI preview.

3. Model Architecture:
3.1 UNet
- Encoder-decoder with skip connections.
- Input: 1-channel grayscale image (L).
- Output: 2-channel color prediction (ab).
- Preserves spatial details via skip connections.
- Convolution blocks followed by ReLU and batch normalization.

3.2 Tiny Perceptual Network (Optional)
- Used to compute perceptual loss for visually pleasing results.
- Two convolutional layers followed by MaxPooling at two stages.
- Helps model focus on high-level visual features beyond pixel-wise differences.

4. Loss Functions:
- L1 Loss: Pixel-wise difference between predicted 'ab' and ground truth.
- Perceptual Loss: L1 difference on features from Tiny Perceptual Network.
- Total loss: loss = L1 + 0.2 * perceptual_loss

5. GUI Features:
- Dark mode with modern color scheme.
- Scrollable display for multiple images.
- Three columns for each row:
  - Grayscale Input
  - Ground Truth
  - Colorized Output
- Automatic colorization when images are loaded.
- Load default test dataset or custom images.
- Displays PSNR and SSIM per image and overall.
- Efficient preview: displays only first 50 images.

5.1 UX Enhancements Added:
- Automatic layout adjustments for multiple images.
- Metrics displayed clearly beside each row.
- First image preview on load.
- Hover effects and consistent color scheme for better readability.

6. Evaluation Metrics:
- PSNR (Peak Signal-to-Noise Ratio): Measures pixel-level fidelity.
- SSIM (Structural Similarity Index): Measures perceptual similarity.
- Both metrics computed for each image and averaged across batch.

7. Project Inspirations:
1. Automatic Colorization with Deep Convolutional Networks – Zhang et al., ECCV 2016
2. Perceptual Losses for Real-Time Style Transfer and Super-Resolution – Johnson et al., ECCV 2016
3. UNet for Image-to-Image Tasks – Ronneberger et al., MICCAI 2015

Unique Contributions:
- Scrollable batch GUI for visualization.
- Automatic colorization without manual intervention.
- Combined PSNR/SSIM display.
- Preview limited to first 50 images to improve speed and usability.
- Clear three-column layout for easy comparison.

8. Future Improvements:
- Video colorization support.
- VGG-based perceptual loss for improved realism.
- Adaptive histogram/color hints for small datasets.
- Real-time high-resolution inference optimization.
